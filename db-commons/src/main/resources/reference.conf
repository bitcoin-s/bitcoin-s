bitcoin-s {

  network = regtest # regtest, testnet3, mainnet, signet
  datadir = ${HOME}".bitcoin-s/"
  sqlite = {
    dataSourceClass = slick.jdbc.DatabaseUrlDataSource
    profile = "slick.jdbc.SQLiteProfile$"

    db {
      //for information on parameters available here see
      //https://scala-slick.org/doc/3.3.1/api/index.html#slick.jdbc.JdbcBackend$DatabaseFactoryDef@forConfig(String,Config,Driver,ClassLoader):Database
      path = ${bitcoin-s.datadir}/${bitcoin-s.network}/
      driver = org.sqlite.JDBC
      user = ""
      password = ""

      # this needs to be set to 1 for SQLITE as it does not support concurrent database operations
      # see: https://github.com/bitcoin-s/bitcoin-s/pull/1840
      numThreads = 1
      queueSize=5000
      connectionPool = disabled
    }
  }

  node = ${bitcoin-s.sqlite}

  node {
    peers = ["localhost"] # a list of peer addresses in form "hostname:portnumber"
                          # (e.g. "neutrino.testnet3.suredbits.com:18333")
                          # Port number is optional, the default value is 8333 for mainnet,
                          # 18333 for testnet and 18444 for regtest.
    mode = neutrino # neutrino, spv
    # this config key is read by Slick
    db {
      name = nodedb.sqlite
      url = "jdbc:sqlite:"${bitcoin-s.node.db.path}${bitcoin-s.node.db.name}
    }
    # PostgreSQL example:
    # db {
    #   url = "jdbc:postgresql://localhost:5432/node"
    #   driver = org.postgresql.Driver
    #   username = postgres
    #   password = ""
    # }
  }


  chain = ${bitcoin-s.sqlite}
  chain {
    neutrino {
      filter-header-batch-size.default = 2000
      filter-header-batch-size.regtest = 10
      # You can set a network specific filter-header-batch-size
      # by adding a trailing `.networkId` (main, test, regtest)
      # It is recommended to keep the main and test batch size high
      # to keep the sync time fast, however, for regtest it should be small
      # so it does not exceed the chain size.

      filter-batch-size = 100
    }
    # this config key is read by Slick
    db {
      name = chaindb.sqlite
      url = "jdbc:sqlite:"${bitcoin-s.chain.db.path}${bitcoin-s.chain.db.name}
    }
    # PostgreSQL example:
    # db {
    #   url = "jdbc:postgresql://localhost:5432/chain"
    #   driver = org.postgresql.Driver
    #   username = postgres
    #   password = ""
    # }
  }

  wallet = ${bitcoin-s.sqlite}
    # settings for wallet module
  wallet {
      defaultAccountType = legacy # legacy, segwit, nested-segwit

      bloomFalsePositiveRate = 0.0001 # percentage

      addressGapLimit = 20

      discoveryBatchSize = 100

      requiredConfirmations = 6
      # How big the address queue size is before we throw an exception
      # because of an overflow
      addressQueueSize = 10

      # How long we attempt to generate an address for
      # before we timeout
      addressQueueTimeout = 5 seconds

    # this config key is read by Slick
    db {
      name = walletdb.sqlite
      url = "jdbc:sqlite:"${bitcoin-s.wallet.db.path}${bitcoin-s.wallet.db.name}
    }
    # PostgreSQL example:
    # db {
    #   url = "jdbc:postgresql://localhost:5432/wallet"
    #   driver = org.postgresql.Driver
    #   username = postgres
    #   password = ""
    # }
  }

    server {
        # The port we bind our rpc server on
        rpcport = 9999
    }


  oracle = ${bitcoin-s.sqlite}
  oracle {
    # this config key is read by Slick
    db {
      name = oracle.sqlite
      url = "jdbc:sqlite:"${bitcoin-s.oracle.db.path}${bitcoin-s.oracle.db.name}
    }
    # PostgreSQL example:
    # db {
    #   url = "jdbc:postgresql://localhost:5432/oracle"
    #   driver = org.postgresql.Driver
    #   username = postgres
    #   password = ""
    # }
  }

  test = ${bitcoin-s.sqlite}
  test {
    # this config key is read by Slick
    db {
      name = testdb.sqlite
      url = "jdbc:sqlite:"${bitcoin-s.test.db.path}${bitcoin-s.test.db.name}
    }
  }
}

akka {

  # Loggers to register at boot time (akka.event.Logging$DefaultLogger logs
  # to STDOUT)
  loggers = ["akka.event.slf4j.Slf4jLogger"]

  # Log level used by the configured loggers (see "loggers") as soon
  # as they have been started; before that, see "stdout-loglevel"
  # Options: OFF, ERROR, WARNING, INFO, DEBUG
  loglevel = "DEBUG"

  # Log level for the very basic logger activated during ActorSystem startup.
  # This logger prints the log messages to stdout (System.out).
  # Options: OFF, ERROR, WARNING, INFO, DEBUG
  stdout-loglevel = "DEBUG"

  # Filter of log events that is used by the LoggingAdapter before
  # publishing log events to the eventStream.
  logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"

  use-slf4j = on

  log-config-on-start = off

    actor {
        debug {
            # enable DEBUG logging of all AutoReceiveMessages (Kill, PoisonPill etc.)
            autoreceive= off
            # enable function of LoggingReceive, which is to log any received message at
            # DEBUG level
            receive = on
            # enable DEBUG logging of unhandled messages
            unhandled = off

            # enable DEBUG logging of actor lifecycle changes
            lifecycle = off

            event-stream=off
        }
    }
}